{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPool2D\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "img_rows=img_cols=28    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Add a convolutional layer (15 units)\n",
    "model.add(Conv2D(15,kernel_size=2,activation='relu', input_shape=(img_rows,img_cols,1)))\n",
    "\n",
    "\n",
    "# Add another convolutional layer (5 units)\n",
    "model.add(Conv2D(5,kernel_size=2,activation='relu'))\n",
    "\n",
    "# Flatten and feed to output layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import ast\n",
    "path_train=\"data/fashion_train_data.txt\"\n",
    "path_label=\"data/fashion_train_label.txt\"\n",
    "\n",
    "with open(path_train, 'r') as f:\n",
    "    train_data = np.array(ast.literal_eval(f.read()))\n",
    "\n",
    "with open(path_label, 'r') as f:\n",
    "    train_labels = np.array(ast.literal_eval(f.read()))\n",
    "    \n",
    "path_test=\"data/fashion_test_data.txt\"\n",
    "with open(path_test, 'r') as f:\n",
    "    test_data = np.array(ast.literal_eval(f.read()))\n",
    "\n",
    "test_labels=np.array([[0., 0., 1.],\n",
    "                      [0., 0., 1.],\n",
    "                      [0., 1., 0.],\n",
    "                      [0., 0., 1.],\n",
    "                      [1., 0., 0.],\n",
    "                      [0., 1., 0.],\n",
    "                      [1., 0., 0.],\n",
    "                      [1., 0., 0.],\n",
    "                      [0., 0., 1.],\n",
    "                      [1., 0., 0.]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit the model to training data \n",
    "model.fit(train_data, train_labels, \n",
    "          validation_split=0.2, \n",
    "          epochs=3, batch_size=10)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "model.evaluate(test_data, test_labels, batch_size=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(10, kernel_size=2, activation='relu', \n",
    "                 input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(10, kernel_size=2, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Summarize the model \n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import ast\n",
    "path=\"data/image.txt\"\n",
    "\n",
    "\n",
    "with open(path, 'r') as f:\n",
    "    im = np.array(ast.literal_eval(f.read()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#im in shape 128X128\n",
    "\n",
    "im=im[0:128,0:128]\n",
    "im.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# Result placeholder\n",
    "result = np.zeros((im.shape[0]//2, im.shape[1]//2))\n",
    "\n",
    "# Pooling operation\n",
    "for ii in range(result.shape[0]):\n",
    "    for jj in range(result.shape[1]):\n",
    "        result[ii, jj] = np.max(im[ii*2:ii*2+2,jj*2:jj*2+2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "plt.imshow(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import ast\n",
    "path_train=\"data/fashion_train_data.txt\"\n",
    "path_label=\"data/fashion_train_label.txt\"\n",
    "\n",
    "with open(path_train, 'r') as f:\n",
    "    train_data = np.array(ast.literal_eval(f.read()))\n",
    "\n",
    "with open(path_label, 'r') as f:\n",
    "    train_labels = np.array(ast.literal_eval(f.read()))\n",
    "    \n",
    "path_test=\"data/fashion_test_data.txt\"\n",
    "with open(path_test, 'r') as f:\n",
    "    test_data = np.array(ast.literal_eval(f.read()))\n",
    "\n",
    "test_labels=np.array([[0., 0., 1.],\n",
    "                      [0., 0., 1.],\n",
    "                      [0., 1., 0.],\n",
    "                      [0., 0., 1.],\n",
    "                      [1., 0., 0.],\n",
    "                      [0., 1., 0.],\n",
    "                      [1., 0., 0.],\n",
    "                      [1., 0., 0.],\n",
    "                      [0., 0., 1.],\n",
    "                      [1., 0., 0.]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Add a convolutional layer\n",
    "model.add(Conv2D(15, kernel_size=2, activation='relu', \n",
    "                 input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "# Add a pooling operation\n",
    "model.add(MaxPool2D(2))\n",
    "\n",
    "# Add another convolutional layer\n",
    "model.add(Conv2D(5,kernel_size=2,activation='relu'))\n",
    "\n",
    "# Flatten and feed to output layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# Fit to training data\n",
    "model.fit(train_data,train_labels,epochs=3,validation_split=0.2,batch_size=10)\n",
    "\n",
    "# Evaluate on test data \n",
    "model.evaluate(test_data,test_labels,batch_size=10)\n",
    "\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
