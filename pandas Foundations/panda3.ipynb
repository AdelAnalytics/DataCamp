{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df=pd.read_csv('data/weather_data_austin_2010.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "date_list=df.Date.tolist()\n",
    "temperature_list= df.Temperature.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Prepare a format string: time_format\n",
    "time_format = '%Y-%m-%d %H:%M'\n",
    "\n",
    "# Convert date_list into a datetime object: my_datetimes\n",
    "my_datetimes = pd.to_datetime(date_list,format=time_format)  \n",
    "\n",
    "# Construct a pandas Series using temperature_list and my_datetimes: time_series\n",
    "time_series = pd.Series(temperature_list, index=my_datetimes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time_format = '%Y-%m-%d %H:%M'\n",
    "df['Date'] = pd.to_datetime(df['Date'],format=time_format)\n",
    "df.index=df['Date']\n",
    "df=df[['Temperature']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ts0=df\n",
    "# Extract the hour from 9pm to 10pm on '2010-10-11': ts1\n",
    "ts1 = ts0.loc['2010-10-11 21:00:00':'2010-10-11 22:00:00']\n",
    "\n",
    "# Extract '2010-07-04' from ts0: ts2\n",
    "ts2 = ts0.loc['2010-07-04']\n",
    "\n",
    "# Extract data from '2010-12-15' to '2010-12-31': ts3\n",
    "ts3 = ts0.loc['2010-12-15':'2010-12-31']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time_format = '%Y-%m-%d'\n",
    "ts1=pd.read_csv('data/ts1.csv')\n",
    "ts2=pd.read_csv('data/ts2.csv')\n",
    "\n",
    "ts1['Date'] = pd.to_datetime(ts1['Date'],format=time_format)\n",
    "ts1.index=ts1['Date']\n",
    "ts1=ts1.drop('Date',axis=1)\n",
    "ts2['Date'] = pd.to_datetime(ts2['Date'],format=time_format)\n",
    "ts2.index=ts2['Date']\n",
    "ts2=ts2.drop('Date',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reindex without fill method: ts3\n",
    "ts3 = ts2.reindex(ts1.index)\n",
    "\n",
    "# Reindex with fill method, using forward fill: ts4\n",
    "ts4 = ts2.reindex(ts1.index,method=\"ffill\")\n",
    "\n",
    "# Combine ts1 + ts2: sum12\n",
    "sum12 = ts1 + ts2\n",
    "\n",
    "# Combine ts1 + ts3: sum13\n",
    "sum13 = ts1 + ts3\n",
    "\n",
    "# Combine ts1 + ts4: sum14\n",
    "sum14 = ts1 + ts4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=pd.read_csv('data/weather_data_austin_2010.csv')\n",
    "time_format = '%Y-%m-%d %H:%M'\n",
    "df['Date'] = pd.to_datetime(df['Date'],format=time_format)\n",
    "df.index=df['Date']\n",
    "df=df.drop('Date',axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Downsample to 6 hour data and aggregate by mean: df1\n",
    "df1 = df['Temperature'].resample('6h').mean()\n",
    "\n",
    "# Downsample to daily data and count the number of data points: df2\n",
    "df2 = df['Temperature'].resample('D').count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Extract temperature data for August: august\n",
    "august = df['Temperature'].loc['2010-08']\n",
    "\n",
    "# Downsample to obtain only the daily highest temperatures in August: august_highs\n",
    "august_highs = august.resample('D').max()\n",
    "\n",
    "# Extract temperature data for February: february\n",
    "february = df['Temperature'].loc['2010-02']\n",
    "\n",
    "# Downsample to obtain the daily lowest temperatures in February: february_lows\n",
    "february_lows = february.resample('D').min()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Extract data from 2010-Aug-01 to 2010-Aug-15: unsmoothed\n",
    "unsmoothed = df['Temperature']['2010-Aug-01':'2010-Aug-15']\n",
    "\n",
    "# Apply a rolling mean with a 24 hour window: smoothed\n",
    "smoothed = unsmoothed.rolling(24).mean()\n",
    "\n",
    "# Create a new DataFrame with columns smoothed and unsmoothed: august\n",
    "august = pd.DataFrame({'smoothed':smoothed, 'unsmoothed':unsmoothed})\n",
    "\n",
    "# Plot both smoothed and unsmoothed data using august.plot().\n",
    "august.plot()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Extract the August 2010 data: august\n",
    "august = df['Temperature']['2010-08']\n",
    "\n",
    "# Resample to daily data, aggregating by max: daily_highs\n",
    "daily_highs = august.resample('D').max()\n",
    "\n",
    "# Use a rolling 7-day window with method chaining to smooth the daily high temperatures in August\n",
    "daily_highs_smoothed = daily_highs.rolling(7).mean()\n",
    "print(daily_highs_smoothed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df=pd.read_csv('https://assets.datacamp.com/production/repositories/497/datasets/5b808399816c8dcb8eef08336595ef9b4eb22902/austin_airport_departure_data_2015_july.csv',header=10)\n",
    "#df=df.drop(1740)\n",
    "#df.to_csv('data/austin_airport_departure_data_2015_july.csv',index=False)\n",
    "\n",
    "df=pd.read_csv('data/austin_airport_departure_data_2015_july.csv')\n",
    "datecol='Date (MM/DD/YYYY)'\n",
    "#time_format = '%d-%m-%Y'\n",
    "df[datecol] = pd.to_datetime(df[datecol])\n",
    "df.index=df[datecol]\n",
    "df=df.drop(datecol,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Strip extra whitespace from the column names: df.columns\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Extract data for which the destination airport is Dallas: dallas\n",
    "dallas = df['Destination Airport'].str.contains('DAL')\n",
    "\n",
    "# Compute the total number of Dallas departures each day: daily_departures\n",
    "daily_departures = dallas.resample('D').sum()\n",
    "\n",
    "# Generate the summary statistics for daily Dallas departures: stats\n",
    "stats = daily_departures.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "time_format = '%Y-%m-%d'\n",
    "ts1=pd.read_csv('data/ts1.csv')\n",
    "ts2=pd.read_csv('data/ts2.csv')\n",
    "\n",
    "ts1['Date'] = pd.to_datetime(ts1['Date'],format=time_format)\n",
    "ts1.index=ts1['Date']\n",
    "ts1=ts1.drop('Date',axis=1)\n",
    "ts2['Date'] = pd.to_datetime(ts2['Date'],format=time_format)\n",
    "ts2.index=ts2['Date']\n",
    "ts2=ts2.drop('Date',axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reset the index of ts2 to ts1, and then use linear interpolation to fill in the NaNs: ts2_interp\n",
    "ts2_interp = ts2.reindex(ts1.index).interpolate(how='linear')\n",
    "\n",
    "# Compute the absolute difference of ts1 and ts2_interp: differences \n",
    "differences = np.abs(ts1-ts2_interp)\n",
    "\n",
    "# Generate and print summary statistics of the differences\n",
    "print(differences.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=pd.read_csv('data/austin_airport_departure_data_2015_july.csv')\n",
    "#datecol='Date (MM/DD/YYYY)'\n",
    "##time_format = '%d-%m-%Y'\n",
    "#df[datecol] = pd.to_datetime(df[datecol])\n",
    "#df.index=df[datecol]\n",
    "#df=df.drop(datecol,axis=1)\n",
    "df.columns = df.columns.str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build a Boolean mask to filter out all the 'LAX' departure flights: mask\n",
    "mask = df['Destination Airport'] == 'LAX'\n",
    "\n",
    "# Use the mask to subset the data: la\n",
    "la = df[mask]\n",
    "\n",
    "# Combine two columns of data to create a datetime series: times_tz_none \n",
    "times_tz_none = pd.to_datetime( la['Date (MM/DD/YYYY)'] + ' ' + la['Wheels-off Time'] )\n",
    "\n",
    "# Localize the time to US/Central: times_tz_central\n",
    "times_tz_central = times_tz_none.dt.tz_localize('US/Central')\n",
    "\n",
    "# Convert the datetimes from US/Central to US/Pacific\n",
    "times_tz_pacific = times_tz_central.dt.tz_convert('US/Pacific')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=pd.read_csv('data/weather_data_austin_2010.csv')\n",
    "df=df[['Temperature','Date']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the raw data before setting the datetime index\n",
    "df.plot()\n",
    "plt.show()\n",
    "\n",
    "# Convert the 'Date' column into a collection of datetime objects: df.Date\n",
    "df.Date = pd.to_datetime(df.Date)\n",
    "\n",
    "# Set the index to be the converted 'Date' column\n",
    "df.set_index('Date',inplace=True)\n",
    "\n",
    "# Re-plot the DataFrame to see that the axis is now datetime aware!\n",
    "df.plot()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Plot the summer data\n",
    "df.Temperature['2010-Jun':'2010-Aug'].plot()\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "# Plot the one week data\n",
    "df.Temperature['2010-06-10':'2010-06-17'].plot()\n",
    "plt.show()\n",
    "plt.clf()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
