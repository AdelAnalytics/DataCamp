{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Oct 31 09:46:58 2019\n",
    "\n",
    "@author: mor\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import relu\n",
    "import torchvision\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_layer = torch.tensor([[ 0.0401, -0.9005,  0.0397, -0.0876]])\n",
    "weight_1=torch.tensor([[-0.1094, -0.8285,  0.0416, -1.1222],\n",
    "                       [ 0.3327, -0.0461,  1.4473, -0.8070],\n",
    "                       [ 0.0681, -0.7058, -1.8017,  0.5857],\n",
    "                       [ 0.8764,  0.9618, -0.4505,  0.2888]])\n",
    "\n",
    "weight_2=torch.tensor([[ 0.6856, -1.7650,  1.6375, -1.5759],\n",
    "                       [-0.1092, -0.1620,  0.1951, -0.1169],\n",
    "                       [-0.5120,  1.1997,  0.8483, -0.2476],\n",
    "                       [-0.3369,  0.5617, -0.6658,  0.2221]])\n",
    "\n",
    "weight_3=torch.tensor([[ 0.8824,  0.1268,  1.1951,  1.3061],\n",
    "                       [-0.8753, -0.3277, -0.1454, -0.0167],\n",
    "                       [ 0.3582,  0.3254, -1.8509, -1.4205],\n",
    "                       [ 0.3786,  0.5999, -0.5665, -0.3975]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the first and second hidden layer\n",
    "hidden_1 = torch.matmul(input_layer, weight_1)\n",
    "hidden_2 = torch.matmul(hidden_1, weight_2)\n",
    "\n",
    "# Calculate the output\n",
    "print(torch.matmul(hidden_2, weight_3))\n",
    "\n",
    "# Calculate weight_composed_1 and weight\n",
    "weight_composed_1 = torch.matmul(weight_1, weight_2)\n",
    "weight = torch.matmul(weight_composed_1, weight_3)\n",
    "\n",
    "# Multiply input_layer with weight\n",
    "print(torch.matmul(input_layer, weight))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from torch import relu\n",
    "\n",
    "# Apply non-linearity on hidden_1 and hidden_2\n",
    "hidden_1_activated = relu(torch.matmul(input_layer, weight_1))\n",
    "hidden_2_activated = relu(torch.matmul(hidden_1_activated, weight_2))\n",
    "print(torch.matmul(hidden_2_activated, weight_3))\n",
    "\n",
    "# Apply non-linearity in the product of first two weights. \n",
    "weight_composed_1_activated = relu(torch.matmul(weight_1, weight_2))\n",
    "\n",
    "# Multiply `weight_composed_1_activated` with `weight_3\n",
    "weight = torch.matmul(weight_composed_1_activated, weight_3)\n",
    "\n",
    "# Multiply input_layer with weight\n",
    "print(torch.matmul(input_layer, weight))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Instantiate ReLU activation function as relu\n",
    "relu = nn.ReLU()\n",
    "\n",
    "# Initialize weight_1 and weight_2 with random numbers\n",
    "weight_1 = torch.rand(4, 6)\n",
    "weight_2 = torch.rand(6, 2)\n",
    "\n",
    "# Multiply input_layer with weight_1\n",
    "hidden_1 = torch.matmul(input_layer, weight_1)\n",
    "\n",
    "# Apply ReLU activation function over hidden_1 and multiply with weight_2\n",
    "hidden_1_activated = relu(hidden_1)\n",
    "print(torch.matmul(hidden_1_activated, weight_2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize the scores and ground truth\n",
    "logits = torch.tensor([[-1.2, 0.12, 4.8]])\n",
    "ground_truth = torch.tensor([2])\n",
    "\n",
    "# Instantiate cross entropy loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Compute and print the loss\n",
    "loss = criterion(logits, ground_truth)\n",
    "print(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Import torch and torch.nn\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "# Initialize logits and ground truth\n",
    "logits = torch.rand(1,1000)\n",
    "ground_truth = torch.tensor([111])\n",
    "\n",
    "# Instantiate cross-entropy loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Calculate and print the loss\n",
    "loss = criterion(logits,ground_truth)\n",
    "print(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Transform the data to torch tensors and normalize it \n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                                    #mean and std normalize\n",
    "\t\t\t\t\t\t\t\ttransforms.Normalize((0.1307,), ((0.3081,)))])\n",
    "\n",
    "# Prepare the datasets\n",
    "trainset = torchvision.datasets.MNIST('mnist', train=True, \n",
    "\t\t\t\t\t\t\t\t\t  download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST('mnist', train=False, \n",
    "\t\t\t\t\t\t\t\t\t  download=True, transform=transform)\n",
    "\n",
    "# Prepare the dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
    "\t\t\t\t\t\t\t\t\t\t  shuffle=True, num_workers=0)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
    "\t\t\t\t\t\t\t\t\t\t shuffle=False, num_workers=0)       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Compute the shape of the training set and testing set\n",
    "trainset_shape = trainloader.dataset.data.shape\n",
    "testset_shape = testloader.dataset.data.shape\n",
    "\n",
    "# Print the computed shapes\n",
    "print(trainset_shape, testset_shape)\n",
    "\n",
    "# Compute the size of the minibatch for training set and testing set\n",
    "trainset_batchsize = trainloader.batch_size\n",
    "testset_batchsize = testloader.batch_size\n",
    "\n",
    "# Print sizes of the minibatch\n",
    "print(trainset_batchsize, testset_batchsize)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the class Net\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):    \n",
    "    \t# Define all the parameters of the net\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28 * 1, 200)\n",
    "        self.fc2 = nn.Linear(200, 10)\n",
    "\n",
    "    def forward(self, x):   \n",
    "    \t# Do the forward pass\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = Net()\n",
    "\n",
    "#data sample\n",
    "train_loader = [iter(trainloader).next() for i in range(50)]\n",
    "test_loader = [iter(testloader).next() for i in range(50)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from torch import optim\n",
    "\n",
    "# Instantiate the Adam optimizer and Cross-Entropy loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "  \n",
    "for batch_idx, data_target in enumerate(train_loader):\n",
    "    data = data_target[0]\n",
    "    target = data_target[1]\n",
    "\n",
    "    #reshape the tensor\n",
    "    data = data.view(-1, 28 * 28)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Complete a forward pass\n",
    "    output = model(data)\n",
    "\n",
    "    # Compute the loss, gradients and change the weights\n",
    "    loss = criterion(output,target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set the model in eval mode \n",
    "#set the model on testing mode (dropout for example behave different on the train and test procedures)\n",
    "model.eval()\n",
    "total=0\n",
    "correct=0\n",
    "for i, data in enumerate(test_loader, 0):\n",
    "    inputs, labels = data\n",
    "    \n",
    "    # Put each image into a vector # flatten the image\n",
    "    inputs = inputs.view(-1, 28*28)\n",
    "    \n",
    "    # Do the forward pass and get the predictions\n",
    "    outputs = model(inputs)\n",
    "    _, outputs = torch.max(outputs.data,axis = 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (outputs == labels).sum().item()\n",
    "print('The testing set accuracy of the network is: %d %%' % (100 * correct / total))\n",
    "\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
