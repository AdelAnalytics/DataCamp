{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Sep 18 16:06:29 2019\n",
    "\n",
    "@author: mor\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report , confusion_matrix , precision_recall_curve\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score , roc_auc_score , average_precision_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "filenames=glob.glob('data\\\\chapter_2\\\\*.csv')\n",
    "filenames = sorted(filenames)\n",
    "df = pd.read_csv(filenames[-1])\n",
    "\n",
    "X=df.drop(['V1','Class'],axis=1).values\n",
    "y=df.Class.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.8904109589041\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Count the total number of observations from the length of y\n",
    "total_obs = len(y)\n",
    "\n",
    "# Count the total number of non-fraudulent observations \n",
    "non_fraud = [i for i in y if i == 0]\n",
    "count_non_fraud = non_fraud.count(0)\n",
    "\n",
    "# Calculate the percentage of non fraud observations in the dataset\n",
    "percentage = (float(count_non_fraud)/float(total_obs)) * 100\n",
    "\n",
    "# Print the percentage: this is our \"natural accuracy\" by doing nothing\n",
    "print(percentage)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Import the random forest model from sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Split your data into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Define the model as the random forest\n",
    "model = RandomForestClassifier(n_estimators=10 ,random_state=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9904109589041096\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Fit the model to our training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtain predictions from the test data \n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "# Print the accuracy performance metric\n",
    "print(accuracy_score(y_test, predicted))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9338879319822626\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      2099\n",
      "           1       0.96      0.80      0.87        91\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      2190\n",
      "   macro avg       0.98      0.90      0.93      2190\n",
      "weighted avg       0.99      0.99      0.99      2190\n",
      "\n",
      "[[2096    3]\n",
      " [  18   73]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Import the packages to get the different performance metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Obtain the predictions from our random forest model \n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "# Predict probabilities\n",
    "probs = model.predict_proba(X_test)\n",
    "\n",
    "# Print the ROC curve, classification report and confusion matrix\n",
    "print(roc_auc_score(y_test, probs[:,1]))\n",
    "print(classification_report(y_test, predicted))\n",
    "print(confusion_matrix(y_test, predicted))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_pr_curve(recall, precision, average_precision):\n",
    "  plt.step(recall, precision, color='b', alpha=0.2, where='post')\n",
    "  plt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\n",
    "  plt.xlabel('Recall')\n",
    "  plt.ylabel('Precision')\n",
    "  plt.ylim([0.0, 1.05])\n",
    "  plt.xlim([0.0, 1.0])\n",
    "  plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(average_precision))\n",
    "  plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Calculate average precision and the PR curve\n",
    "average_precision = average_precision_score(y_test, predicted)\n",
    "\n",
    "# Obtain precision and recall \n",
    "precision, recall, _ = precision_recall_curve(y_test, predicted)\n",
    "\n",
    "# Plot the recall precision tradeoff\n",
    "plot_pr_curve(recall, precision, average_precision)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9347962661445273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      2099\n",
      "           1       0.99      0.79      0.88        91\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      2190\n",
      "   macro avg       0.99      0.90      0.94      2190\n",
      "weighted avg       0.99      0.99      0.99      2190\n",
      "\n",
      "[[2098    1]\n",
      " [  19   72]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the model with balanced subsample\n",
    "model = RandomForestClassifier(class_weight='balanced_subsample',n_estimators=10 , random_state=5)\n",
    "\n",
    "# Fit your training model to your training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtain the predicted values and probabilities from the model \n",
    "predicted = model.predict(X_test)\n",
    "probs = model.predict_proba(X_test)\n",
    "\n",
    "# Print the roc_auc_score, the classification report and confusion matrix\n",
    "print(roc_auc_score(y_test, probs[:,1]))\n",
    "print(classification_report(y_test, predicted))\n",
    "print(confusion_matrix(y_test, predicted))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_proba_valid(model):\n",
    "    if type(model).__name__=='VotingClassifier' and model.voting=='hard':\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def get_model_results(X_train, y_train, X_test, y_test, model):\n",
    "  model.fit(X_train, y_train)\n",
    "  predicted = model.predict(X_test)\n",
    "  \n",
    "  if check_proba_valid(model):\n",
    "      probs = model.predict_proba(X_test)\n",
    "      print('\\n\\n')\n",
    "      print(roc_auc_score(y_test, probs[:,1]))\n",
    "  print (classification_report(y_test, predicted))\n",
    "  print (confusion_matrix(y_test, predicted))\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "0.9609651901219315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      2099\n",
      "           1       0.97      0.85      0.91        91\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      2190\n",
      "   macro avg       0.98      0.92      0.95      2190\n",
      "weighted avg       0.99      0.99      0.99      2190\n",
      "\n",
      "[[2097    2]\n",
      " [  14   77]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Change the model options\n",
    "model = RandomForestClassifier(bootstrap=True, class_weight={0:1, 1:12}, criterion='entropy',\n",
    "\t\t\t\n",
    "\t\t\t# Change depth of model\n",
    "            max_depth=10,\n",
    "\t\t\n",
    "\t\t\t# Change the number of samples in leaf nodes\n",
    "            min_samples_leaf=10, \n",
    "\n",
    "\t\t\t# Change the number of trees to use\n",
    "            n_estimators=20, n_jobs=-1, random_state=5)\n",
    "\n",
    "# Run the function get_model_results\n",
    "get_model_results(X_train, y_train, X_test, y_test, model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 8,\n",
       " 'max_features': 'log2',\n",
       " 'n_estimators': 30}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the parameter sets to test\n",
    "param_grid = {'n_estimators': [1, 30], 'max_features': ['auto', 'log2'],  'max_depth': [4, 8], 'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Define the model to use\n",
    "model = RandomForestClassifier(random_state=5)\n",
    "\n",
    "# Combine the parameter sets with the defined model\n",
    "CV_model = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='recall', n_jobs=-1)\n",
    "\n",
    "# Fit the model to our training data and obtain best parameters\n",
    "CV_model.fit(X_train, y_train)\n",
    "CV_model.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "0.9749697658225529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      2099\n",
      "           1       0.95      0.84      0.89        91\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      2190\n",
      "   macro avg       0.97      0.92      0.94      2190\n",
      "weighted avg       0.99      0.99      0.99      2190\n",
      "\n",
      "[[2095    4]\n",
      " [  15   76]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Input the optimal parameters in the model\n",
    "model = RandomForestClassifier(class_weight={0:1,1:12}, criterion='gini',\n",
    "            max_depth=8, max_features='log2',  min_samples_leaf=10, n_estimators=30, n_jobs=-1, random_state=5)\n",
    "\n",
    "# Get results from your model\n",
    "get_model_results(X_train, y_train, X_test, y_test, model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "0.9722054981702433\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      2099\n",
      "           1       0.63      0.88      0.73        91\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      2190\n",
      "   macro avg       0.81      0.93      0.86      2190\n",
      "weighted avg       0.98      0.97      0.98      2190\n",
      "\n",
      "[[2052   47]\n",
      " [  11   80]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the Logistic Regression model with weights\n",
    "model = LogisticRegression(class_weight={0:1, 1:15}, random_state=5)\n",
    "\n",
    "# Get the model results\n",
    "get_model_results(X_train, y_train, X_test, y_test, model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2099\n",
      "           1       0.90      0.86      0.88        91\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      2190\n",
      "   macro avg       0.95      0.93      0.94      2190\n",
      "weighted avg       0.99      0.99      0.99      2190\n",
      "\n",
      "[[2090    9]\n",
      " [  13   78]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Import the package\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Define the three classifiers to use in the ensemble\n",
    "clf1 = LogisticRegression(class_weight={0:1, 1:15}, random_state=5)\n",
    "clf2 = RandomForestClassifier(class_weight={0:1, 1:12}, criterion='gini', max_depth=8, max_features='log2',\n",
    "            min_samples_leaf=10, n_estimators=30, n_jobs=-1, random_state=5)\n",
    "clf3 = DecisionTreeClassifier(random_state=5, class_weight=\"balanced\")\n",
    "\n",
    "# Combine the classifiers in the ensemble model\n",
    "ensemble_model = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('dt', clf3)], voting='hard')\n",
    "\n",
    "# Get the results \n",
    "get_model_results(X_train, y_train, X_test, y_test, ensemble_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "0.9739279300975348\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      2099\n",
      "           1       0.94      0.85      0.89        91\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      2190\n",
      "   macro avg       0.97      0.92      0.94      2190\n",
      "weighted avg       0.99      0.99      0.99      2190\n",
      "\n",
      "[[2094    5]\n",
      " [  14   77]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the ensemble model\n",
    "ensemble_model = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='soft', weights=[1, 4, 1], flatten_transform=True)\n",
    "\n",
    "# Get results \n",
    "get_model_results(X_train, y_train, X_test, y_test, ensemble_model)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
